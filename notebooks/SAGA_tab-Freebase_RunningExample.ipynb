{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib import URIRef\n",
    "from rdflib.namespace import OWL, RDF, RDFS,XSD, Namespace\n",
    "import csv\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import HGBDataset\n",
    "\n",
    "HGBDataset(root='.',name=\"Freebase\").process()\n",
    "complete_data = torch.load('./freebase/processed/data.pt')[0]\n",
    "for k in complete_data.node_types:\n",
    "    complete_data[k].x = torch.Tensor([[1] for i in range(complete_data[k].num_nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAPH PREPROCESSING: REMOVE SELF LOOPS AND ISOLATED NODES\n",
    "from torch_geometric.utils import remove_self_loops, remove_isolated_nodes\n",
    "\n",
    "for edge_type in complete_data.edge_index_dict.keys():\n",
    "    if edge_type[0] == edge_type[2]:\n",
    "        new_edge_index = remove_self_loops(complete_data[edge_type].edge_index)[0]\n",
    "        complete_data[edge_type].edge_index = new_edge_index\n",
    "    new_edge_index = remove_isolated_nodes(complete_data[edge_type].edge_index)[0]\n",
    "    complete_data[edge_type].edge_index = new_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = list(complete_data.edge_index_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE ROOT IN A DICT TO NOT LOST THEM DURING THE GNN COMPUTATION\n",
    "root_nodes_types = {}\n",
    "for node_type in complete_data.x_dict.keys():\n",
    "    i = 0\n",
    "    for edge_t in edge_types:\n",
    "        if node_type == edge_t[2]: break \n",
    "        i+=1\n",
    "    if i == len(edge_types):\n",
    "        root_nodes_types[node_type] = complete_data.x_dict[node_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPPING FROM RELATION TYPE TO AN INT\n",
    "\n",
    "rel_to_index = {edge_t:i for edge_t,i in zip(edge_types,range(len(edge_types)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HeteroConv, GATConv, Linear\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, edge_types, root_nodes_types):\n",
    "        super().__init__()\n",
    "        g = torch.manual_seed(0)\n",
    "        self.conv1 = HeteroConv({edge_t: GATConv((1, 1) ,hidden_channels,add_self_loops=False) for edge_t in edge_types})\n",
    "        self.conv2 = HeteroConv({edge_t: GATConv((hidden_channels, hidden_channels), out_channels,add_self_loops=False) for edge_t in edge_types})\n",
    "        self.rel_weight = torch.nn.Parameter(torch.randn(len(edge_types), out_channels, generator=g))\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, data):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        for t,v in root_nodes_types.items(): #RE-ADD ROOT NODES THAT ARE DISCARDED BY DEFAULT\n",
    "            x_dict[t] = v\n",
    "        x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        \n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        for t,v in root_nodes_types.items():\n",
    "            x_dict[t] = v\n",
    "            \n",
    "        out = x_dict\n",
    "    \n",
    "        pred_dict = {}\n",
    "        ### LINK PREDICTION ACTS HERE ###\n",
    "        for edge_t in edge_types:\n",
    "            #Compute link embedding for each edge type\n",
    "            #for src in train_link[edge_t].edge_label_index[0]:\n",
    "            out_src = out[edge_t[0]][data[edge_t].edge_label_index[0]]#embedding src nodes\n",
    "            out_dst = out[edge_t[2]][data[edge_t].edge_label_index[1]] #embedding dst nodes\n",
    "        \n",
    "            # LINK EMBEDDING #\n",
    "            # 2- Distmult with random initialized rel weights\n",
    "            #r = torch.Tensor([self.rel_weight[rel_to_index[edge_t]].detach().numpy() for z in range(len(out_src))])\n",
    "            out_sim = torch.sum(out_src * self.rel_weight[rel_to_index[edge_t]] * out_dst, dim=-1)\n",
    "            pred = out_sim\n",
    "        \n",
    "            pred_dict[edge_t] = pred\n",
    "        return pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "device = torch.device('cuda')\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeteroGNN(hidden_channels=4, out_channels=2, \n",
    "                  edge_types=edge_types,\n",
    "                  root_nodes_types=root_nodes_types)\n",
    "\n",
    "model.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT THE KG IN TRAIN AND TEST SET\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "link_split = RandomLinkSplit(num_val=0.0,\n",
    "                             num_test=0.25,\n",
    "                             edge_types=edge_types,\n",
    "                             rev_edge_types=[None]*len(edge_types))\n",
    "train_link, val_link, test_link = link_split(complete_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(train_link.x_dict,train_link.edge_index_dict, train_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSE AN OPTIMIZER AND TRAINING HYPERPARAMETERS\n",
    "weight_decay=5e-4\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=weight_decay)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01, weight_decay = weight_decay)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=0.1, weight_decay = weight_decay)\n",
    "#optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01, weight_decay=weight_decay)\n",
    "criterion =  torch.nn.BCEWithLogitsLoss() #change loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hetlinkpre():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    pred_dict = model(train_link.x_dict, train_link.edge_index_dict, train_link)  # Perform a single forward pass.\n",
    "    edge_labels = torch.Tensor()\n",
    "    preds = torch.Tensor()\n",
    "    for edge_t in edge_types:\n",
    "        preds = torch.cat((preds,pred_dict[edge_t]),-1)\n",
    "        edge_labels = torch.cat((edge_labels,train_link[edge_t].edge_label.type_as(pred_dict[edge_t])),-1)\n",
    "    #compute loss function based on all edge types\n",
    "    loss = criterion(preds, edge_labels)\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def test_hetlinkpre(test_link,evaluate='linkpre'):\n",
    "    if evaluate not in ['linkpre','propdetection','all']:\n",
    "        #linkpre: link between entities\n",
    "        #propdetection: link between an entity and a property\n",
    "        #all: both \n",
    "        raise NotImplementedError()\n",
    "    model.eval()\n",
    "    hs_dict = model(test_link.x_dict, test_link.edge_index_dict, test_link) #obtain edge embeddings of the test set\n",
    "    hs = torch.Tensor([])\n",
    "    edge_labels = np.array([])\n",
    "    ### LINK PREDICTION ACTS HERE ###\n",
    "    #evaluate distincly entity-to-entity link prediction and entity-to-property(property-detection)\n",
    "    prop = ['String','Integer','Double','gYear','Date'] #add other property types if used\n",
    "    rel_with_prop = [edge_t for edge_t in edge_types if edge_t[2] in prop]\n",
    "    if evaluate == 'linkpre':\n",
    "        edge_types_to_evaluate = [edge_t for edge_t in edge_types if edge_t not in rel_with_prop]\n",
    "    elif evaluate == 'propdetection':\n",
    "        edge_types_to_evaluate = rel_with_prop\n",
    "    else:\n",
    "        edge_types_to_evaluate = edge_types\n",
    "    for edge_t in edge_types_to_evaluate:\n",
    "        hs = torch.cat((hs,hs_dict[edge_t]),-1)\n",
    "        edge_labels = np.concatenate((edge_labels,test_link[edge_t].edge_label.cpu().detach().numpy()))\n",
    "    \n",
    "    \n",
    "    pred_cont = torch.sigmoid(hs).cpu().detach().numpy()\n",
    "    \n",
    "    # EVALUATION\n",
    "    if evaluate=='propdetection':\n",
    "        test_roc_score = average_precision_score(edge_labels, pred_cont)\n",
    "    else:\n",
    "        test_roc_score = roc_auc_score(edge_labels, pred_cont) #compute AUROC score for test set\n",
    "    \n",
    "    return test_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_train = []\n",
    "perf_test = []\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_hetlinkpre()\n",
    "    roc_train = test_hetlinkpre(train_link)\n",
    "    roc_test = test_hetlinkpre(test_link)\n",
    "    perf_train.append(roc_train)\n",
    "    perf_test.append(roc_test)\n",
    "    #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, ROC train: {roc_train:.4f}, ROC test: {roc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_train = test_hetlinkpre(train_link,evaluate='linkpre')\n",
    "roc_test = test_hetlinkpre(test_link,evaluate='linkpre')\n",
    "print(f'Train AUROC: {roc_train:.4f}\\nTest AUROC: {roc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(num_epochs)\n",
    "plt.clf()\n",
    "plt.plot(x, perf_train, color='orange', label='auroc_train')\n",
    "plt.plot(x, perf_test, color='blue', label='auroc_test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUROC-score')\n",
    "plt.legend()\n",
    "plt.ylim(top=1)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed8a8f81fdcbe4bb580e703d3d81905dffa90d7a53be09b673d3f1a6169b3bc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
